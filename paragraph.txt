Hi there. In this video, we are going to learn about Latency-based Routing Policy. If your application is hosted in multiple AWS regions, this policy helps improve performance for the users by serving their request from the AWS region that provides the lowest latency to the user. So how does it do it? Well, first you create a latency records for your resources in multiple AWS regions. Then, when the route 53 receives a DNS query for the domain, it determines which region gives the user the lowest latency, and then selects a latency record for that region. And finally, route 53 responds with the value from that selected record, such as the IP address of a web server. We are going to see this in a live demonstration in just a few minutes. The scenarios in which this policy is useful, is basically any application that is deployed in multiple regions and requires a response from the resources in terms of milliseconds or even microseconds. For example, streaming media or online gaming applications would definitely benefit from latency-based routing policy. To demonstrate how the latency-based routing policy works, I will be setting up this scenario. Basically, I'll be creating two A records. The first A record will be a latency record for us-east-2 region. I will be creating an instance in that region as well. The second A record will be a latency based record for eu-west-3 or Paris region, which will have an instance created in that region as well. After setting these A records, when a user tries to go to this whizlabstest.com, that route 53 is first going to see the region to which the user belongs, in this case is us-east-1. The route 53 is going to then calculate the latency between the region of the origin which is us-east-1 and us-east-2. Let's say that latency is X. Route 53 is also going to calculate the latency between region us-east-1 and eu-west-3. Let's call that as Y. If the X is less than Y, that means the latency between us-east-1 and us-east-2 is lesser. So the traffic will be routed to us-east-2 region. However, if the latency Y is less than X that means the latency between the regions us-east-1, and eu-west-3 is lesser, so the traffic will be routed to eu-west-3. So in this scenario, most likely the traffic will be routed to us-east-2 region because geographically these two regions are closer to each other. However, this is not always guaranteed. So note that, the latency calculation between host on internet can change over time as a result of changes in network connectivity and routing. Also, latency measurements performed are over a period of time, it's not at that moment when the request comes. Similarly, let's say that in this scenario, a user from eu-west-2 region or London region sends a request to this whizlabstest.com. The route 53 is again going to calculate the latency between eu-west-2 and us-east-2 as well as between eu-west-2 and eu-west-3. Most likely in this situation, the latency between eu-west-2 and eu-west-3 is going to be lesser, so the traffic will be forwarded to the instance in France or in Paris region. Let's create this scenario and see what happens. I am in AWS console and in Ohio region, I have created an instance that is Instance1. If you go there, it is going to display a text as this instance is in USA. Similarly, in the Paris region or eu-west-3, i have created another server which just displays a text, instance is in France. Now let us go to route 53. Go to the hosted zone, and let's create a record set. Keep the type as A record. I'm going to reduce the time to leave. The value for the first record is going to be the IP address of our instance, that is in United States of America. Select routing policy as latency. Now select the region to which this instance belongs. It has automatically selected us-east-2. So, I'm going to keep that. Give it an ID. Go ahead and create it. Similarly, let us add a record for Paris region. Select the region to which this instance belongs. Give it an ID. And create it. Now let us go ahead and test this using the test record set feature of route 53. Select the type as A record. Now here is what I'm going to do. I'm going to use an IP address that belong to a region, let's say in Canada and see where the request gets routed to. I am going to use this website which gives me few IP addresses that belong to Canada region. So just grab any IP address, go to route 53 and use this as the resolver IP address and hit 'Get response.' And you can see that the response written by route 53 is an IP address that belongs to the us-west-2 region. Now, let us select a region that is closer to Paris region. How about London region? So here I have few IP addresses that belong to United Kingdom. Let's grab any one of them. Use that IP address as the resolver IP address. And there you go. The response written by route 53 is the IP address that belong to the instance in Paris. So, it is evident that the request of getting routed based on the origin IP addresses region, and the two regions in which we have set up the latency records. Go ahead and play with it. Use different IP addresses that belong to different regions and see where the request gets routed to. You will notice that the latencies can be calculated based on the position where the regions are and more often than not, the request will go to the region that is closer to the origin of the DNS query. And that's exactly how latency-based routing works. 